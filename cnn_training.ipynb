{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-22T15:31:09.761998Z",
     "start_time": "2025-04-22T15:31:08.491848Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from CNN import AudioClassifier\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from custom_dataset import SpectrogramDataset, BinaryDataset, create_sampler\n",
    "from training_pipeline import repeat_training, set_seed, worker_init_fn, plot_results\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Parameters",
   "id": "83efdef3ae450654"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T15:31:09.813772Z",
     "start_time": "2025-04-22T15:31:09.763002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "repetitions = 4\n",
    "lr = 0.001\n",
    "epochs = 100\n",
    "tolerance = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "alpha = 1\n",
    "dropout = 0.3\n",
    "weight_decay = 0.0001\n",
    "augmented_fraction = 0.5\n",
    "label_smoothing = 0.1\n",
    "\n",
    "batch_size = 1024\n",
    "n_workers = 4\n",
    "prefetch_factor = 2 if n_workers > 0 else None\n",
    "persistent_workers = True if n_workers > 0 else False"
   ],
   "id": "345eff81e3102c8f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10 classes + unknown",
   "id": "15f94a773795d102"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T15:22:05.628220Z",
     "start_time": "2025-04-22T15:21:48.555881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = \"data/train/audio_transformed\"\n",
    "train_dataset = SpectrogramDataset(data_path, set_type=SpectrogramDataset.TRAIN, augmentation=True, augmented_fraction=augmented_fraction)\n",
    "val_dataset = SpectrogramDataset(data_path, set_type=SpectrogramDataset.VAL)\n",
    "test_dataset = SpectrogramDataset(data_path, set_type=SpectrogramDataset.TEST)\n",
    "\n",
    "sampler = create_sampler(train_dataset, alpha)\n",
    "train_loader = DataLoader(train_dataset, sampler=sampler, batch_size=batch_size, shuffle=False, num_workers=n_workers, pin_memory=True, prefetch_factor=prefetch_factor,persistent_workers=persistent_workers, worker_init_fn=worker_init_fn)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=n_workers, pin_memory=True, prefetch_factor=prefetch_factor, persistent_workers=persistent_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=n_workers, pin_memory=True, prefetch_factor=prefetch_factor, persistent_workers=persistent_workers)"
   ],
   "id": "7ea9406109ade0b3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T15:22:47.917794Z",
     "start_time": "2025-04-22T15:22:05.819113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def init_cnn_all_classes():\n",
    "     return AudioClassifier(num_classes=11, drop=dropout)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "model_dir = f\"output/models/all_classes/final/cnn\"\n",
    "history_dir = f\"output/history/all_classes/final/cnn\"\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "model_path = model_dir + \"/cnn.pth\"\n",
    "history_path = history_dir + \"/cnn.pkl\"\n",
    "\n",
    "repeat_training(repetitions, init_cnn_all_classes, lr, model_path, history_path, epochs, train_loader, val_loader, test_loader, device, tolerance=tolerance, weight_decay=weight_decay, label_smoothing=label_smoothing)"
   ],
   "id": "96b52c87d08d8488",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training iteration: 1 of 4\n",
      "starting training...\n",
      "epoch: 1, training loss: 0.002289330211695257, training accuracy: 14.357579079235828, training balanced accuracy: 14.358138315684712\n",
      "epoch: 1, validation loss: 0.002432755141722591, validation accuracy: 9.944101206237129, validation balanced accuracy: 23.721408018578856\n",
      "model saved\n",
      "\n",
      "epoch: 2, training loss: 0.0021288441736198615, training accuracy: 22.3614155966176, training balanced accuracy: 22.174287799510676\n",
      "epoch: 2, validation loss: 0.00232615701308423, validation accuracy: 13.033245072080023, validation balanced accuracy: 31.19589957315798\n",
      "model saved\n",
      "\n",
      "epoch: 3, training loss: 0.0019948937178516776, training accuracy: 29.35327278421547, training balanced accuracy: 29.1880138111524\n",
      "epoch: 3, validation loss: 0.002148007217243371, validation accuracy: 18.181818181818183, validation balanced accuracy: 42.496035043095155\n",
      "model saved\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m model_path \u001B[38;5;241m=\u001B[39m model_dir \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/cnn.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     13\u001B[0m history_path \u001B[38;5;241m=\u001B[39m history_dir \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/cnn.pkl\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 15\u001B[0m repeat_training(repetitions, init_cnn_all_classes, lr, model_path, history_path, epochs, train_loader, val_loader, test_loader, device, tolerance\u001B[38;5;241m=\u001B[39mtolerance, weight_decay\u001B[38;5;241m=\u001B[39mweight_decay, label_smoothing\u001B[38;5;241m=\u001B[39mlabel_smoothing)\n",
      "File \u001B[1;32mD:\\Studia\\semestr8\\deep_learning_project_2\\training_pipeline.py:53\u001B[0m, in \u001B[0;36mrepeat_training\u001B[1;34m(n, init_model, lr, model_path, history_path, epochs, train_dataloader, val_dataloader, test_dataloader, device, dropout, betas, weight_decay, tolerance, label_smoothing)\u001B[0m\n\u001B[0;32m     51\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstarting training...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 53\u001B[0m training_history \u001B[38;5;241m=\u001B[39m train(epochs, model, train_dataloader, val_dataloader, optimizer, criterion, device,\n\u001B[0;32m     54\u001B[0m                          model_path_idx, tolerance)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining finished\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28mprint\u001B[39m(training_history)\n",
      "File \u001B[1;32mD:\\Studia\\semestr8\\deep_learning_project_2\\training_functions.py:70\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(epochs, model, train_dataloader, val_dataloader, optimizer, criterion, device, model_path, tolerance)\u001B[0m\n\u001B[0;32m     67\u001B[0m epochs_without_improvement \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m---> 70\u001B[0m     train_accuracy, train_avg_loss, train_balanced_acc \u001B[38;5;241m=\u001B[39m training_epoch(model, train_dataloader, optimizer, criterion, device)\n\u001B[0;32m     71\u001B[0m     train_accuracy_list\u001B[38;5;241m.\u001B[39mappend(train_accuracy)\n\u001B[0;32m     72\u001B[0m     train_loss_list\u001B[38;5;241m.\u001B[39mappend(train_avg_loss)\n",
      "File \u001B[1;32mD:\\Studia\\semestr8\\deep_learning_project_2\\training_functions.py:21\u001B[0m, in \u001B[0;36mtraining_epoch\u001B[1;34m(model, dataloader, optimizer, criterion, device)\u001B[0m\n\u001B[0;32m     18\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     19\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 21\u001B[0m epoch_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m     22\u001B[0m _, predicted \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mmax(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     23\u001B[0m correct \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m predicted\u001B[38;5;241m.\u001B[39meq(y)\u001B[38;5;241m.\u001B[39msum()\u001B[38;5;241m.\u001B[39mitem()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10 classes",
   "id": "28a84da05ca20968"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T15:28:07.038337Z",
     "start_time": "2025-04-22T15:28:00.355270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = \"data/train/audio_transformed\"\n",
    "train_dataset = SpectrogramDataset(data_path, set_type=SpectrogramDataset.TRAIN, augmentation=True, augmented_fraction=augmented_fraction, use_unknown=False)\n",
    "val_dataset = SpectrogramDataset(data_path, set_type=SpectrogramDataset.VAL, use_unknown=False)\n",
    "test_dataset = SpectrogramDataset(data_path, set_type=SpectrogramDataset.TEST, use_unknown=False)\n",
    "\n",
    "sampler = create_sampler(train_dataset, alpha)\n",
    "train_loader = DataLoader(train_dataset, sampler=sampler, batch_size=batch_size, shuffle=False, num_workers=n_workers, pin_memory=True, prefetch_factor=prefetch_factor,persistent_workers=persistent_workers, worker_init_fn=worker_init_fn)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=n_workers, pin_memory=True, prefetch_factor=prefetch_factor, persistent_workers=persistent_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=n_workers, pin_memory=True, prefetch_factor=prefetch_factor, persistent_workers=persistent_workers)"
   ],
   "id": "29911de221c8fab5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-04-22T15:29:04.790932800Z",
     "start_time": "2025-04-22T15:28:08.730913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def init_cnn_without_unknown():\n",
    "     return AudioClassifier(num_classes=10, drop=dropout)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "model_dir = f\"output/models/without_unknown/final/cnn\"\n",
    "history_dir = f\"output/history/without_unknown/final/cnn\"\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "model_path = model_dir + \"/cnn.pth\"\n",
    "history_path = history_dir + \"/cnn.pkl\"\n",
    "\n",
    "repeat_training(repetitions, init_cnn_without_unknown, lr, model_path, history_path, epochs, train_loader, val_loader, test_loader, device, tolerance=tolerance, weight_decay=weight_decay, label_smoothing=label_smoothing)"
   ],
   "id": "a9dffa6da9c25e1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training iteration: 1 of 4\n",
      "starting training...\n",
      "epoch: 1, training loss: 0.002330244224117031, training accuracy: 13.313194519365627, training balanced accuracy: 13.294825365324561\n",
      "epoch: 1, validation loss: 0.0025997006435194447, validation accuracy: 15.289095847885138, validation balanced accuracy: 15.252407750613575\n",
      "model saved\n",
      "\n",
      "epoch: 2, training loss: 0.0022907563559457778, training accuracy: 16.096666307044988, training balanced accuracy: 16.123512783981433\n",
      "epoch: 2, validation loss: 0.0024243471092339586, validation accuracy: 23.088863019014358, validation balanced accuracy: 22.993101910870255\n",
      "model saved\n",
      "\n",
      "epoch: 3, training loss: 0.0022450334651015675, training accuracy: 19.014996223972382, training balanced accuracy: 19.051850149748248\n",
      "epoch: 3, validation loss: 0.002408158052878922, validation accuracy: 22.894838960031045, validation balanced accuracy: 22.8438396988337\n",
      "model saved\n",
      "\n",
      "epoch: 4, training loss: 0.002181763414400837, training accuracy: 21.631243931384184, training balanced accuracy: 21.536514417306314\n",
      "epoch: 4, validation loss: 0.00234971196326721, validation accuracy: 27.86185487000388, validation balanced accuracy: 27.90896884650662\n",
      "model saved\n",
      "\n",
      "epoch: 5, training loss: 0.0021352831735260112, training accuracy: 23.292696083719928, training balanced accuracy: 23.29138492269606\n",
      "epoch: 5, validation loss: 0.002099444202827214, validation accuracy: 34.84672099340318, validation balanced accuracy: 35.066957686391596\n",
      "model saved\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m model_path \u001B[38;5;241m=\u001B[39m model_dir \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/cnn.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     13\u001B[0m history_path \u001B[38;5;241m=\u001B[39m history_dir \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/cnn.pkl\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 15\u001B[0m repeat_training(repetitions, init_cnn_without_unknown, lr, model_path, history_path, epochs, train_loader, val_loader, test_loader, device, tolerance\u001B[38;5;241m=\u001B[39mtolerance, weight_decay\u001B[38;5;241m=\u001B[39mweight_decay, label_smoothing\u001B[38;5;241m=\u001B[39mlabel_smoothing)\n",
      "File \u001B[1;32mD:\\Studia\\semestr8\\deep_learning_project_2\\training_pipeline.py:53\u001B[0m, in \u001B[0;36mrepeat_training\u001B[1;34m(n, init_model, lr, model_path, history_path, epochs, train_dataloader, val_dataloader, test_dataloader, device, dropout, betas, weight_decay, tolerance, label_smoothing)\u001B[0m\n\u001B[0;32m     51\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstarting training...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 53\u001B[0m training_history \u001B[38;5;241m=\u001B[39m train(epochs, model, train_dataloader, val_dataloader, optimizer, criterion, device,\n\u001B[0;32m     54\u001B[0m                          model_path_idx, tolerance)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining finished\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28mprint\u001B[39m(training_history)\n",
      "File \u001B[1;32mD:\\Studia\\semestr8\\deep_learning_project_2\\training_functions.py:70\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(epochs, model, train_dataloader, val_dataloader, optimizer, criterion, device, model_path, tolerance)\u001B[0m\n\u001B[0;32m     67\u001B[0m epochs_without_improvement \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m---> 70\u001B[0m     train_accuracy, train_avg_loss, train_balanced_acc \u001B[38;5;241m=\u001B[39m training_epoch(model, train_dataloader, optimizer, criterion, device)\n\u001B[0;32m     71\u001B[0m     train_accuracy_list\u001B[38;5;241m.\u001B[39mappend(train_accuracy)\n\u001B[0;32m     72\u001B[0m     train_loss_list\u001B[38;5;241m.\u001B[39mappend(train_avg_loss)\n",
      "File \u001B[1;32mD:\\Studia\\semestr8\\deep_learning_project_2\\training_functions.py:21\u001B[0m, in \u001B[0;36mtraining_epoch\u001B[1;34m(model, dataloader, optimizer, criterion, device)\u001B[0m\n\u001B[0;32m     18\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     19\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 21\u001B[0m epoch_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m     22\u001B[0m _, predicted \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mmax(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     23\u001B[0m correct \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m predicted\u001B[38;5;241m.\u001B[39meq(y)\u001B[38;5;241m.\u001B[39msum()\u001B[38;5;241m.\u001B[39mitem()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Binary case",
   "id": "1ebf97026bef2eac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T15:31:31.564472Z",
     "start_time": "2025-04-22T15:31:14.709753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = \"data/train/audio_transformed\"\n",
    "train_dataset = BinaryDataset(data_path, set_type=SpectrogramDataset.TRAIN, augmentation=True, augmented_fraction=augmented_fraction)\n",
    "val_dataset = BinaryDataset(data_path, set_type=SpectrogramDataset.VAL)\n",
    "test_dataset = BinaryDataset(data_path, set_type=SpectrogramDataset.TEST)\n",
    "\n",
    "sampler = create_sampler(train_dataset, alpha)\n",
    "train_loader = DataLoader(train_dataset, sampler=sampler, batch_size=batch_size, shuffle=False, num_workers=n_workers, pin_memory=True, prefetch_factor=prefetch_factor,persistent_workers=persistent_workers, worker_init_fn=worker_init_fn)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=n_workers, pin_memory=True, prefetch_factor=prefetch_factor, persistent_workers=persistent_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=n_workers, pin_memory=True, prefetch_factor=prefetch_factor, persistent_workers=persistent_workers)"
   ],
   "id": "5bcce5201aff1c1e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T15:32:36.078015Z",
     "start_time": "2025-04-22T15:31:51.347544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def init_cnn_binary():\n",
    "     return AudioClassifier(num_classes=2, drop=dropout)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "model_dir = f\"output/models/binary/final/cnn\"\n",
    "history_dir = f\"output/history/binary/final/cnn\"\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "model_path = model_dir + \"/cnn.pth\"\n",
    "history_path = history_dir + \"/cnn.pkl\"\n",
    "\n",
    "repeat_training(repetitions, init_cnn_binary, lr, model_path, history_path, epochs, train_loader, val_loader, test_loader, device, tolerance=tolerance, weight_decay=weight_decay, label_smoothing=label_smoothing)"
   ],
   "id": "67e2b9fd11465195",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training iteration: 1 of 4\n",
      "starting training...\n",
      "epoch: 1, training loss: 0.000677801558973645, training accuracy: 51.44456623864704, training balanced accuracy: 51.44461379113672\n",
      "epoch: 1, validation loss: 0.0007163865508735793, validation accuracy: 49.07325684024713, validation balanced accuracy: 53.927656467923704\n",
      "model saved\n",
      "\n",
      "epoch: 2, training loss: 0.0006770348491953938, training accuracy: 52.403695584090194, training balanced accuracy: 52.398821742415855\n",
      "epoch: 2, validation loss: 0.0007207519203538438, validation accuracy: 47.74933804060018, validation balanced accuracy: 53.82883795998664\n",
      "\n",
      "epoch: 3, training loss: 0.0006747268691000952, training accuracy: 53.562480425931724, training balanced accuracy: 53.464036979752485\n",
      "epoch: 3, validation loss: 0.0007029189787110219, validation accuracy: 56.29596940276552, validation balanced accuracy: 51.99046344859769\n",
      "model saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
