{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-08T16:50:00.900876Z",
     "start_time": "2025-04-08T16:49:59.824215Z"
    }
   },
   "source": [
    "from CNN import AudioClassifier\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from custom_dataset import SpectrogramDataset\n",
    "from training_pipeline import repeat_training"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T16:50:01.230751Z",
     "start_time": "2025-04-08T16:50:00.900876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = \"data/train/audio_transformed\"\n",
    "train_dataset = SpectrogramDataset(data_path, set_type=SpectrogramDataset.TRAIN)\n",
    "val_dataset = SpectrogramDataset(data_path, set_type=SpectrogramDataset.VAL)\n",
    "test_dataset = SpectrogramDataset(data_path, set_type=SpectrogramDataset.TEST)\n",
    "\n",
    "batch_size = 32\n",
    "n_workers = 8\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=n_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=n_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=n_workers, pin_memory=True)"
   ],
   "id": "4700a23d971078ab",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T16:39:37.103012Z",
     "start_time": "2025-04-08T16:39:27.744935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ],
   "id": "409a7d52c4028627",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 201, 81]) torch.Size([32])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T16:50:12.043962Z",
     "start_time": "2025-04-08T16:50:01.725506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "repetitions = 4\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_dir = \"output/models/cnn\"\n",
    "history_dir = \"output/history/cnn\"\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "model_path = model_dir + \"/cnn.pth\"\n",
    "history_path = history_dir + \"/cnn.pkl\"\n",
    "\n",
    "repeat_training(repetitions, AudioClassifier, lr, model_path, history_path, epochs, train_loader, val_loader, test_loader, device)"
   ],
   "id": "67ef37774cf7e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training iteration: 1 of 4\n",
      "starting training...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 4 is not equal to len(dims) = 3",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m model_path \u001B[38;5;241m=\u001B[39m model_dir \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/cnn.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     13\u001B[0m history_path \u001B[38;5;241m=\u001B[39m history_dir \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/cnn.pkl\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 15\u001B[0m repeat_training(repetitions, AudioClassifier, lr, model_path, history_path, epochs, train_loader, val_loader, test_loader, device)\n",
      "File \u001B[1;32mD:\\Studia\\semestr8\\deep_learning_project_2\\training_pipeline.py:37\u001B[0m, in \u001B[0;36mrepeat_training\u001B[1;34m(n, init_model, lr, model_path, history_path, epochs, train_dataloader, val_dataloader, test_dataloader, device, dropout, betas, weight_decay, tolerance)\u001B[0m\n\u001B[0;32m     35\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstarting training...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 37\u001B[0m training_history \u001B[38;5;241m=\u001B[39m train(epochs, model, train_dataloader, val_dataloader, optimizer, criterion, device,\n\u001B[0;32m     38\u001B[0m                          model_path_idx, tolerance)\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining finished\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28mprint\u001B[39m(training_history)\n",
      "File \u001B[1;32mD:\\Studia\\semestr8\\deep_learning_project_2\\training_functions.py:58\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(epochs, model, train_dataloader, val_dataloader, optimizer, criterion, device, model_path, tolerance)\u001B[0m\n\u001B[0;32m     55\u001B[0m epochs_without_improvement \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m---> 58\u001B[0m     train_accuracy, train_avg_loss \u001B[38;5;241m=\u001B[39m training_epoch(model, train_dataloader, optimizer, criterion, device)\n\u001B[0;32m     59\u001B[0m     train_accuracy_list\u001B[38;5;241m.\u001B[39mappend(train_accuracy)\n\u001B[0;32m     60\u001B[0m     train_loss_list\u001B[38;5;241m.\u001B[39mappend(train_avg_loss)\n",
      "File \u001B[1;32mD:\\Studia\\semestr8\\deep_learning_project_2\\training_functions.py:12\u001B[0m, in \u001B[0;36mtraining_epoch\u001B[1;34m(model, dataloader, optimizer, criterion, device)\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x, y \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[0;32m     11\u001B[0m     x, y \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mto(device), y\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 12\u001B[0m     output \u001B[38;5;241m=\u001B[39m model(x)\n\u001B[0;32m     13\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(output, y)\n\u001B[0;32m     15\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\Studia\\semestr8\\deep_learning_project_2\\CNN.py:43\u001B[0m, in \u001B[0;36mAudioClassifier.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 43\u001B[0m     x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     45\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdrop1(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn1(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1(x)))    \n\u001B[0;32m     46\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdrop2(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn2(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(x)))   \n",
      "\u001B[1;31mRuntimeError\u001B[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 4 is not equal to len(dims) = 3"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
